# -*- coding: utf-8 -*-
# OPENCLASSROOMS-COURSES-EXPLORER 
# Copyright (c) 2021, Tristan Vanrullen - all rights reserved.
# Note there is a licence for the code and another for the contents generated by the application
# see licence.txt for more details 


from OCCoursesConfig import pd, requests, webdriver,WebDriverWait, FirefoxWebdriverPath, ec, By, html, json, time, date, datetime
import OCCoursesDatasets as ocd # to have datasets available everywhere read+write and avoid "global" keyword for each of them
# save_OC_datasets,\
#     OC_Topics , OC_Paths, OC_PathsSkills, OC_Projects, OC_ProjectsSkills, OC_Courses, OC_CoursesSkills, \
#     OC_CoursesParts, OC_CoursesChapters, OC_ProjectsCoursesLinks,OC_CoursesLinks, OC_MyCourses, \
#     OC_Topics_cols , OC_Paths_cols, OC_PathsSkills_cols, OC_Projects_cols, OC_ProjectsSkills_cols, OC_Courses_cols, OC_CoursesSkills_cols, \
        # OC_CoursesParts_cols, OC_CoursesChapters_cols, OC_ProjectsCoursesLinks_cols,OC_CoursesLinks_cols, OC_MyCourses_cols
# from OCCoursesDatasets import


# ------------------------------------------------- Interaction functions
OC_browser = None # Selenium browser to get logged in pages
OC_connexion_status = False # are we connected to OC or not ?
OC_connexion_info = None # Json table of user information collected when logging with Selenium, containing logout URL with csrf token

# ABANDONNED APPROACH
OC_requests_session = None # to use "requests" driver (instead of Selenium) for basic (not logged in) pages exploration
# / ABANDONNED APPROACH


#Selenium browser tool function to get rid of (cookies) overlays appearing on page load

def OC_browser_hide_overlays(max_wait=10):
    """
    Hide Overlay elements in the OC page

    Parameters
    ----------
    max_wait : TYPE, optional
        DESCRIPTION. The default is 20.

    Returns
    -------
    None.

    """
    global OC_browser
    
    if (type(OC_browser)==type(None)):
        return
    try:
        WebDriverWait(OC_browser, max_wait).until(ec.visibility_of_element_located((By.CLASS_NAME, "truste_overlay")))
        OC_browser.execute_script("var x = document.getElementsByClassName('truste_overlay');\
                                  var i;\
                                  for (i = 0; i < x.length; i++) {\
                                  x[i].style.display = 'none';\
                                  }")
        OC_browser.execute_script("var x = document.getElementsByClassName('truste_box_overlay');\
                                  var i;\
                                  for (i = 0; i < x.length; i++) {\
                                  x[i].style.display = 'none';\
                                  }")
    except:
        pass
# fin fonction

# Selenium browser tool function to test whether connexion is successful and collect user information + links (including logout)
# the JSon information collected contains  : 
#             {
#                 "user": {
#                     "id": 123456789,
#                     "displayableName": "Firstname\u0020Lastname",
#                     "messageCount": 0,
#                     "notificationCount": 0,
#                     "profilePicture": "https://user.oc-static.com/users/avatars/an_avatar_picture.jpg",
#                     "premiumStatus": "plus",
#                     "organizationName": "",
#                     "link": {
#                         "profile": "/fr/members/123456780abc",
#                         "parameter": "/fr/members/123456780abc/parametres",
#                         "logOut": "/logout?_csrf_token=abMdDKlRJBh8Gcpw21Gzxxxx",
#                         "analyticsDashboard": ""
#                     }
#                 },
#                 "right": {
#                     "canSeeMentorDashboard": false,
#                     "canSeeAdminDashboard": false,
#                     "canDisplayForumAlert": false,
#                     "canSeeOrganizationDashboard": false
#                 }
#             }
def OC_browser_collect_connexion_info():
    global  OC_browser, OC_connexion_info, OC_connexion_status
    
    if (type(OC_browser)==type(None)):
        OC_connexion_info = None
        OC_connexion_status = False
        return False
    try:
        e=OC_browser.find_element_by_id("headerConfiguration")  
        OC_connexion_info = json.loads(e.get_attribute('innerHTML')) 
        OC_connexion_status = (OC_connexion_info["user"]["link"]["logOut"] !="")
    except: 
        OC_connexion_info = None
        OC_connexion_status = False
        return False
    return True
# fin fonction

def OC_browser_get_connexion_info():
    return OC_connexion_info

def OC_browser_get_connexion_status():
    return OC_connexion_status
    
# Selenium function to create the web driver and initiate connexion to OpenClassrooms with credentials provided in the widgets
def OC_browser_connect(mylogin,mypassword):
    from OCCoursesInterface  import console_log
    global  OC_browser #FirefoxWebdriverPath
    
    try:
        #initialize the driver if not launched yet
        if (type(OC_browser)==type(None)):
            OC_browser = webdriver.Firefox(executable_path=FirefoxWebdriverPath)

        login_url='https://openclassrooms.com/fr/login'  
        console_log("Browsing "+login_url)

        #print('-------------------------------- Step 1 : loading login page '+login_url)
        OC_browser.get(login_url)
        time.sleep(2) # time gap  

        #print('-------------------------------- Step 2 : cookies GDPR dialog')
        # masquer l'overlay avec JS est plus simple que de chercher Ã  cliquer sur un des boutons
        OC_browser_hide_overlays(20)

        #print('-------------------------------- Step 3 : choose login with email ')
        email_input_box = OC_browser.find_element_by_id("fielduserEmail")
        continue_button = OC_browser.find_element_by_id("continue-button")

        email_input_box.clear() 
        email_input_box.send_keys(mylogin)
        time.sleep(2) # time gap before next step
        #hit the login button
        continue_button.click()
        time.sleep(2) # time gap

        #print('-------------------------------- Step 4 : enter password and connect')
        password_input_box = OC_browser.find_element_by_id("field_password")
        login_button = OC_browser.find_element_by_id("login-button")

        password_input_box.clear() 
        password_input_box.send_keys(mypassword)
        time.sleep(2) # time gap before next step
        #hit the login button
        login_button.click()
        time.sleep(5) # time gap
        OC_browser_hide_overlays()

        #print('-------------------------------- Step 5 : finally get user connexion info')
        success = OC_browser_collect_connexion_info() 
        if success:
            console_log(" ... Login successful!")
        else: 
            console_log(" ... Login error!")
        #
        #print('-------------------------------- end ')
    except:
        console_log(" ... Something went wrong, but we escaped safely! Where are we now?")
# fin fonction

# Selenium function to create the web driver and initiate connexion to OpenClassrooms with credentials provided in the widgets
def OC_browser_get(url,time_gap=2,console_trace=True):
    from OCCoursesInterface  import console_log
    global  OC_browser 
    try:
        #initialize the driver if not launched yet
        if (type(OC_browser)==type(None)):
            OC_browser = webdriver.Firefox(executable_path=FirefoxWebdriverPath)

        if (console_trace):
            console_log("Browsing "+url)
            
        OC_browser.get(url)
        time.sleep(time_gap) # time gap  
        #p = OC_browser.page_source
    except:
        if (console_trace):
            console_log(" ... Something went wrong, but we escaped safely! Where are we now?")
        return False
    return True
# fin fonction


# Selenium function to logout Openclassrooms, using 
def OC_browser_disconnect():
    from OCCoursesInterface  import console_log
    global  OC_browser, OC_connexion_info
    #logout properly before closing browser
    console_log("Quitting Web Driver")
    if (type(OC_connexion_info) != type(None)) and (type(OC_browser) != type(None)):
        console_log("... Logout OC session", False)
        logout_url = OC_connexion_info["user"]["link"]["logOut"]
        console_log("... "+logout_url,False)
        OC_browser.get("https://openclassrooms.com"+logout_url) 
        time.sleep(2)
        console_log("... OK", False)
    if (type(OC_browser) != type(None)):
        console_log("... Closing Marionette Browser", False)
        OC_browser.quit()
        OC_browser = None
        console_log("... OK",False)
    else:
        console_log("... ALREADY DISCONNECTED",False)
    # update connexion info
    OC_browser_collect_connexion_info() 
# fin fonction 


# ABANDONNED APPROACH ! impossible to get javascript & ajax driven data
# --- Connection with "requests module" 
# This function initiates the OC_requests_session variable when necessary
# The the function returns page content located in "url"
def OC_connect_requests_session(url = 'https://openclassrooms.com/fr/'): 
    from OCCoursesInterface  import console_log
    global OC_requests_session 
    
    console_log("Browsing "+url)
    # Fill in your details here to be posted to the login form.
#     payload = {
#         'this': 'that',
#         'these': 'those'
#     }
    payload = {}
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chromium/80.0.3987.160 Chrome/80.0.3987.163 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'fr-FR,fr;q=0.5',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Pragma': 'no-cache',
        'Cache-Control': 'no-cache',
    }
    
    # Use 'with' to ensure the session context is closed after use.
    if (type(OC_requests_session) == type(None)):
        OC_requests_session = requests.Session() 
        OC_requests_session.headers.update(headers)

    p = None
    try:
        p = OC_requests_session.get(url, data=payload) 
        if (p.status_code == requests.codes.ok):
            console_log("... OK",False)
        else:
            console_log("... ERR "+str(p.status_code)+" : "+str(p.reason),False)
    except:
        console_log("... KO",False)
    return p
# fin fonction

def OC_close_requests_session():
    global OC_requests_session
    if (type(OC_requests_session) == type(None)):
        return
    OC_requests_session.close()
    OC_requests_session = None
# fin fonction
# / ABANDONNED APPROACH



# --------------------------------------- OC SCRAPPING
# --- preparing the scrapper
 
#URL racine pour rÃ©cupÃ©rer les infos et projets d'un parcours (paths) 
url_paths = "https://openclassrooms.com/fr/paths/" 

#URL racine pour rÃ©cupÃ©rer les cours et leurs chapitres
url_courses = "https://openclassrooms.com/fr/courses/"

#URL racine pour rÃ©cupÃ©rer les infos de progression  
url_my_paths = "https://openclassrooms.com/fr/dashboard/paths"
url_my_courses = "https://openclassrooms.com/fr/dashboard/courses"

#URL du moteur de recherche polyvalent
url_search = "https://openclassrooms.com/fr/search"
search_page_param="page"
search_topic_param="categories" # 
search_language_param = "language" # fr | en | es
search_language_options = ["fr","en","es"]
search_path_or_course_param="type" # path | course


# --- actions connected with buttons
def scrap_OC_Topics(b):  
    from OCCoursesInterface  import console_log, display_data_status, display_data_section, toggle_scrap_buttons
    global OC_browser, url_search
    success=True #until it gets False
    console_log("Scrapping topics")  
    toggle_scrap_buttons(True)
    
    OC_browser_get(url_search)
    time.sleep(10)
    OC_browser_hide_overlays()
    elts=OC_browser.find_elements_by_xpath('//button[contains(string(),"ThÃ¨me")]/..//following-sibling::ul/li/span/button/span/span')
    data = []
    i=1
    for e in elts: 
        txt = e.get_attribute('innerHTML')
        color = e.value_of_css_property('color')
        if color.find("rgb(")>=0:
            rgbvals=color.replace("rgb(","").replace(")","")
            rgb=rgbvals.split(",")
            hexcolor="#"+"".join('%02x' %int(x) for x in rgb)
            color=hexcolor
        data.append([i,html.unescape(txt),txt,color])
        i+=1
    ocd.OC_Topics=pd.DataFrame(data, columns=ocd.OC_Topics_cols)
    # OC_Topics_cols              = ["topic_id","topic_name","topic_html_name"]
    # OC_Topics                   = pd.DataFrame(columns=OC_Topics_cols)
    OC_browser_disconnect()
    display_data_status()
    display_data_section()
    toggle_scrap_buttons(False)
    return success 
# fin fonction


def scrap_OC_Courses(b):
    from OCCoursesInterface  import console_log, display_data_status, display_data_section, set_progress, clear_progress, init_progress, toggle_scrap_buttons
    global OC_browser, url_courses, url_search, \
        search_language_options, search_topic_param, search_language_param, search_page_param, search_path_or_course_param 
    success=True #until it gets False
    console_log("Scrapping courses")  
    toggle_scrap_buttons(True)
    
    courses = []
    
    # start browser with fresh driver
    OC_browser_get(url_search+"?"+search_path_or_course_param+"=course")
    # the search page provides the total count of search results in a html element appearing only when window is phone-size
    # let's force this element to appear
    bs = OC_browser.get_window_size()
    print(bs)
    OC_browser.set_window_position(0, 0)
    OC_browser.set_window_size(640, 480)
    OC_browser_hide_overlays()
    time.sleep(2)
    nb_courses=0
    elt=OC_browser.find_element_by_xpath('//*[text() = "filtres (1)"]')
    elt.click()
    time.sleep(2)
    elt=OC_browser.find_element_by_xpath('//span[contains(string(),"Voir les")]')
    #elt=OC_browser.find_element_by_class_name("main-header-2-main-header168")
    # le texte ressemble Ã  : "voir les 471 rÃ©sultats"
    # le nb de rÃ©sultats est en 3eme position
    nb_courses=int(elt.text.split(" ")[2])
    # revenir Ã  la taille de dÃ©marrage pour retrouver les Ã©lÃ©ments de notre recherche
    OC_browser.set_window_size(bs["width"],bs["height"])
    init_progress('courses',0,0,nb_courses)
    
    # For each language
    for lang in search_language_options:
        console_log("LANG = "+lang)
        # get the topics available for this language
        OC_browser_get(url_search+"?"+search_language_param+"="+lang+"&"+search_path_or_course_param+"=course")
        time.sleep(2)
        elts=OC_browser.find_elements_by_xpath('//button[contains(string(),"ThÃ¨me")]/..//following-sibling::ul/li/span/button/span/span')
        topics = []
        for e in elts: 
            txt = e.get_attribute('innerHTML')
            topics.append(txt)
        #display("AVAILABLE TOPICS = ")
        #display(topics)
        # for each topic available for the given language
        for topic in topics:
            # identify the corresponding row in ocd.OC_Topics (to have a topic_id)
            topic_id=0
            for j in ocd.OC_Topics.index.values:
                if ocd.OC_Topics.topic_html_name.iloc[j] == topic:
                    topic_id=ocd.OC_Topics.iloc[j]["topic_id"]
                    break
            #display(ocd.OC_Topics.iloc[j])
            console_log("TOPIC = "+str(topic_id)+"/"+topic)
            # then get all search pages for this topic and this lang
            page_has_results=True
            page=1
            while (page_has_results):
                console_log("PAGE = "+str(page))
                page_has_results=False
                OC_browser_get(url_search+"?"+search_language_param+"="+lang+"&"+ \
                               search_path_or_course_param+"=course"+"&"+search_topic_param+"="+ \
                               topic.replace(" &amp; ","%20%26%20")+"&"+search_page_param+"="+str(page))
                time.sleep(2)
                OC_browser_hide_overlays()
                result_elts=OC_browser.find_elements_by_xpath('//a[contains(@href,"/courses/")]') # the 'a' tag containing summary of each course
                for re in result_elts: 
                    page_has_results=True
                    course_url = re.get_attribute('href')
                    # format = xxxxidxxxx-name-of-the-course
                    course_url=course_url.rsplit('/', 1)[-1]
                    course_id=int(course_url.split('-')[0])
                    course_name=course_url.replace(str(course_id)+"-","")
                    course_full_url=url_courses+course_url
                    course_illustration= ""
                    _elt=re.find_element_by_xpath('.//figure')  # 'figure' tag
                    fig_style=_elt.get_attribute("style")
                    if 'background-image' in fig_style:
                        course_illustration = fig_style.split(' url("')[1].replace('");', '')
                    _elt=re.find_element_by_xpath('.//h6')  # 'h6' tag
                    course_title=_elt.text
                    
                    _elts=re.find_elements_by_xpath('.//h6/following-sibling::div/span')
                    vect=[]
                    for _e in _elts:
                        vect.append(_e.text)
                    
                    course_difficulty=""
                    course_duration=""
                    course_duration_hours=0.0
                    course_partner=""
                    if (len(vect)>0):
                        course_difficulty=vect[0]
                    if (len(vect)>1):
                        if ("minutes" in vect[1]) or ("heure" in vect[1]):
                            course_duration=vect[1]
                            val=course_duration.split(" ")[0]
                            unit=course_duration.split(" ")[1]
                            if (unit=="minutes"):
                                course_duration_hours=int(100*float(val)/60)/100
                            else:
                                course_duration_hours=float(val)
                        else: 
                            course_partner=vect[1]
                    if (len(vect)>2):
                        course_partner=vect[2]
                    _elt=re.find_element_by_xpath('.//p')
                    course_description=_elt.text
                    #some data are missing on the search page, so we'll fill the blanks when parsing each course page
                    course_date=""
                    course_author=""
                    course_is_certified=""
                    #["topic_id","course_id","course_name","course_date","course_title","course_description","course_language","course_difficulty","course_duration_hours","course_author","course_partner","course_illustration","course_is_certified","course_url"]
                    course = [topic_id,course_id,course_name,course_date,course_title,course_description,lang,
                              course_difficulty,course_duration_hours,course_author,course_partner,
                              course_illustration,course_is_certified,course_full_url]
                    #display(course)
                    courses.append(course)
                    set_progress(len(courses),'courses')
                #end for page results
                page += 1
            #end while page has results
        # end loop on topics
    # end loop on language
    console_log("DONE :"+str(len(courses))+" courses collected")
    ocd.OC_Courses=pd.DataFrame(courses, columns=ocd.OC_Courses_cols)
    OC_browser_disconnect()
    display_data_status()
    display_data_section()
    clear_progress()
    toggle_scrap_buttons(False)
    return success 
# fin fonction

def scrap_OC_CoursesDetails(b):
    from OCCoursesInterface  import console_log, display_data_status, display_data_section, set_progress, clear_progress, init_progress, toggle_scrap_buttons
    global  OC_browser, url_courses, url_paths, \
        url_search, search_language_options, search_topic_param, search_language_param, search_page_param, search_path_or_course_param\
    
    success=True #until it gets False
    console_log("Scrapping courses details") 
    toggle_scrap_buttons(True)
#     OC_Courses_cols             = ["topic_id","course_id","course_name","course_date","course_title","course_description","course_language","course_difficulty","course_duration_hours","course_author","course_partner","course_illustration","course_is_certified","course_url"]
#     OC_CoursesParts_cols        = ["course_id","part_number","part_name","part_title","part_description","part_url"]
#     OC_CoursesChapters_cols     = ["course_id","part_number","chapter_id","chapter_number","chapter_name","chapter_title","chapter_description","chapter_url"]
#     OC_CoursesSkills_cols      = ["course_id","skill"]
#     OC_CoursesLinks_cols        = ["src_course_id","src_chapter_id","relation","tgt_course_id","tgt_chapter_id"] #will be scrapped in another function     

    
    cp_entries = [] # parts to collect
    cc_entries = [] # chapters to collect
    cs_entries = [] # skills to collect
    
    #start a browser to avoid window loading latency within the loop
    OC_browser_get(url_search)
    
    #create a copy so that we can update the original with its missing contents
    df = ocd.OC_Courses[["topic_id","course_id","course_name","course_title","course_language","course_url"]].copy()
    init_progress('courses details',0,0,len(df))
    counter=0
    # iterate 
    for ind , course in df.iterrows(): 
        counter+=1 
        OC_browser_get(course["course_url"])
        time.sleep(2)
        #OC_browser_hide_overlays() 
        #time.sleep(3)
        course_activities_count=0
        course_exercises_count=0
        
        # now collect info
        course_id=course["course_id"]
        try:
            elts = OC_browser.find_elements_by_xpath("//ul[@class='course js-course-part']/li[contains(@class,'course-part-summary')]/../li")
        except:
            # the course has probably been archived since last visit (see for instance course #4464381)
            console_log("exception when parsing page "+str(course_id))
            continue #jump to next course and ignore this one. 

        for re in elts:
            if (re.get_attribute("class").find("certifying")>0):
                continue
#             print("----")
            e = re.find_element_by_xpath("./section//h3")
            txt=e.text
            t=txt.split(" - ")
            part_number=int(t[0].split(" ")[1])
            part_title=t[1]
#             print([part_number,part_title])
#             print([course_id,part_number,"",part_title,"",""])
            cp_entries.append([course_id,part_number,"",part_title,"",""])
        
            c_elts=re.find_elements_by_xpath(".//ol/li/h4")
            for e in c_elts: 
#                 print("----")
                t=e.text.split(". ") 
                chapter_number = int(t[0])
                chapter_title = t[1]
                he=e.find_element_by_xpath("./a[contains(@href,'courses/')]")
                chapter_url=he.get_attribute("href")
                t=chapter_url.split("/")
                tc =t[len(t)-1]
                t=tc.split("-")
                chapter_id=int(t[0])
                chapter_name=tc.replace(str(chapter_id)+"-","") 
#                 print([course_id,part_number,chapter_id,chapter_number,chapter_name,chapter_title,"",chapter_url])
                cc_entries.append([course_id,part_number,chapter_id,chapter_number,chapter_name,chapter_title,"",chapter_url])
            # end loop on chapters of a part
            
            c_elts=re.find_elements_by_xpath(".//div/ul/li")
            for e in c_elts: 
#                 print("----")
                t=e.text
                he=e.find_element_by_xpath("./a[contains(@href,'courses/')]")
                activity_url=he.get_attribute("href")
                if (activity_url.find("/exercises/")>=0):
                    if t.find('Quiz')>=0:
                        course_exercises_count +=1
                    elif t.find('Acti')>=0:
                        course_activities_count +=1
            # end loop on activities/exercises of a part        
        # end loop on course parts
        
        patterns=["Objectifs","capable de","Learning goals","able to","aprenderÃ¡s lo siguiente"]
        for pat in patterns:
            s_elts=OC_browser.find_elements_by_xpath("//aside[@data-claire-semantic='information']//p[contains(.,'"+pat+"')]/./..//li")
            if (len(s_elts)>0):
                for e in s_elts:
                    #print(e.text)
                    course_skill=e.text
                    cs_entries.append([course_id,course_skill])
                break 
            #end if
        # en loop on skills
        
        # now let's fill some blanks in the course dataframe
        ocd.OC_Courses.loc[ind,"course_activities_count"]=course_activities_count
        ocd.OC_Courses.loc[ind,"course_exercises_count"]=course_exercises_count
        
        try:
            e=OC_browser.find_element_by_class_name("courseHeader__updatedTime")
            t=e.text.split(" ")
            course_date=t[len(t)-1]
            ocd.OC_Courses.loc[ind,"course_date"]=course_date
        except:
            # the course has probably been archived since last visit (see for instance course #4464381)
            console_log("exception when parsing page details (date) "+str(course_id))

        try:
            #/div[@class='courseFooter']/
            elts=OC_browser.find_elements_by_xpath("//div[@class='course-bottom__subtitle' and @itemprop='name']")
            authors=[]
            for e in elts:
                authors.append(e.text)
            course_author="|".join(authors)  
            ocd.OC_Courses.loc[ind,"course_author"]=course_author
        except:
            # the course has probably been archived since last visit (see for instance course #4464381)
            console_log("exception when parsing page details (author) "+str(course_id))

        try:
            course_is_certified=0
            elts = OC_browser.find_elements_by_partial_link_text("Certificat de rÃ©ussite")
            if (len(elts)>0):
                course_is_certified=1
            ocd.OC_Courses.loc[ind,"course_is_certified"]=int(course_is_certified)
        except:
            # the course has probably been archived since last visit (see for instance course #4464381)
            console_log("exception when parsing page details (certified) "+str(course_id))
        set_progress(counter,'courses details')  
#         print([course_id,len(cp_entries),len(cc_entries),len(cs_entries)]) 
    #end iterating over Courses dataframe
    
    console_log("DONE :"+str(len(cp_entries))+" parts + "+str(len(cc_entries))+" chapters + "+str(len(cs_entries))+" skills collected") 
    ocd.OC_CoursesParts=pd.DataFrame(cp_entries, columns=ocd.OC_CoursesParts_cols)
    ocd.OC_CoursesChapters=pd.DataFrame(cc_entries, columns=ocd.OC_CoursesChapters_cols)
    ocd.OC_CoursesSkills=pd.DataFrame(cs_entries, columns=ocd.OC_CoursesSkills_cols)
    OC_browser_disconnect()
    display_data_status()
    display_data_section()
    clear_progress()
    toggle_scrap_buttons(False)
    return success 
# fin fonction     


def extract_course_chapter_link(link_url): 
    
    course_id=0
    chapter_id=0
    #check whether the link is on the OC domain
    if (link_url.find("openclassrooms.com/")>0):
        t=link_url.split("/")
        nb_steps=len(t)
        for i in range(0,nb_steps):
            #first work on the course
            if (t[i]=="courses" or t[i]=="cours"):
                if (i+1 < nb_steps): # if there is something after "courses"
                    tc =t[i+1]
#                     print("looking for course:"+tc)
                    tt=tc.split("-")
                    if (tt[0].isnumeric()):
                        course_id=int(tt[0])
#                         print (course_id)
                    #end course url has a course_id prefix
                    else:
                        df=ocd.OC_Courses[ocd.OC_Courses["course_name"].isin([tc])]
                        if len(df)>0:
                            for ir,row in df.iterrows():
#                                 print(row)
                                course_id=int(row["course_id"])
#                                 print (course_id)
                                break # no need for several answers
                            #end looping on df 
#                         else:
                            #bad news : course not found by its name
#                             print("could not find course id for this path :"+tc)
                            # ex "https://openclassrooms.com/fr/courses/4722851-maitrisez-lunivers-des-cotisations-sociales"
                            #let OC resolve the link for us ?
                    #end course url has no course_id
                #then work on the chapter 
                if (i+2 < nb_steps): # if there is something after "courses/<coursepath>/"
                    tc =t[i+2]
#                     print("looking for chapter:"+tc)
                    tt=tc.split("-")
                    if (tt[0].isnumeric()):
                        chapter_id=int(tt[0])
#                         print (chapter_id)
                    #end chapter url has a chapter_id prefix
                    else:
                        df=ocd.OC_CoursesChapters[ocd.OC_CoursesChapters["course_id"].isin([course_id]) & ocd.OC_CoursesChapters["chapter_name"].isin([tc])]
                        if len(df)>0:
                            for ir,row in df.iterrows():
#                                 print(row)
                                chapter_id=int(row["chapter_id"])
#                                 print (chapter_id)
                                break # no need for several answers
                            #end looping on df 
#                         else:
#                             #bad news : chapter not found by its name
#                             print("could not find chapter id for this path :"+tc)
                            # ex "https://openclassrooms.com/fr/courses/4722851-maitrisez-lunivers-des-cotisations-sociales"
                            #let OC resolve the link for us ?
                    #end course url has no course_id
                #do some stuff
            #end if we found the 'courses' step in the path
        #end for each step in the path
#         print([course_id,chapter_id]) 
    #end if course is on OC domain
#     else:
#         print ("false positive external courses :"+link_url)
    #end if course is not on OC domain
    return course_id, chapter_id
#fin fonction                    


# print("-----------")
# tests = [
#     "https://s3-eu-west-1.amazonaws.com/course.oc-static.com/courses/4929811/Utiliser+les+fonctionnalite%CC%81s+d'Excel_activite%CC%81.xlsx",
#     "https://openclassrooms.com/fr/courses/4525266-decrivez-et-nettoyez-votre-jeu-de-donnees/4928001-decouvrez-les-statistiques-vocabulaire-et-tour-d-horizon",
#     "https://openclassrooms.com/courses/maitrisez-lenvironnement-juridique-de-ladministration-du-personnel",
#     "https://openclassrooms.com/informatique/cours/apprenez-a-creer-votre-site-web-avec-html5-et-css3",
#     "https://openclassrooms.com/fr/courses/4452741-decouvrez-les-librairies-python-pour-la-data-science/5559646-installez-jupyter-sur-votre-propre-ordinateur",
#     "https://openclassrooms.com/courses/initiez-vous-a-lalgebre-relationnelle-avec-le-langage-sql",
#     "https://openclassrooms.com/courses/decouvrez-la-programmation-orientee-objet-avec-python"
# ]
# for t in tests:
#     cid,ccid = extract_course_chapter_link(t)
#     print(cid,ccid,t)
#     print("-----------")


def scrap_OC_CoursesLinks(b):    
    from OCCoursesInterface  import console_log, display_data_status, display_data_section, set_progress, clear_progress, init_progress, toggle_scrap_buttons
    global OC_browser,  url_courses, url_paths, url_search, \
        search_language_options, search_topic_param, search_language_param, search_page_param, search_path_or_course_param\
    
    success=True #until it gets False
    console_log("Scrapping courses links (may take some hours...)") 
    toggle_scrap_buttons(True)
#     OC_Courses_cols             = ["topic_id","course_id","course_name","course_date","course_title","course_description","course_language","course_difficulty","course_duration_hours","course_author","course_partner","course_illustration","course_is_certified","course_url"]
#     OC_CoursesParts_cols        = ["course_id","part_number","part_name","part_title","part_description","part_url"]
#     OC_CoursesChapters_cols     = ["course_id","part_number","chapter_id","chapter_number","chapter_name","chapter_title","chapter_description","chapter_url"]
#     OC_CoursesSkills_cols      = ["course_id","skill"]
#     OC_CoursesLinks_cols        = ["src_course_id","src_chapter_id","relation","tgt_course_id","tgt_chapter_id","href"] 
 
    #start a browser to avoid window loading latency within the loop
    OC_browser_get(url_search)
    
    courses = ocd.OC_Courses[["topic_id","course_id","course_name","course_title","course_language","course_url"]]
#     [OC_Courses["topic_id"].isin([3])]
    chapters = ocd.OC_CoursesChapters[["course_id","part_number","chapter_id","chapter_number","chapter_name","chapter_title","chapter_url"]]
    init_progress('courses links',0,0,len(courses)+len(chapters))
    courses_counter=0
    chapters_counter=0
    required_entries_counter=0
    referenced_entries_counter=0
    # iterate 
    for course_index , course in courses.iterrows(): 
        required_entries = [] # requirement links
        referenced_entries = [] # referenced links
        
        OC_browser_get(course["course_url"])
#         time.sleep(2)
        #OC_browser_hide_overlays() 
        # now collect info
        course_id=course["course_id"]
        
        # 1st page of a course : collect required links and other links

#         print ("parsing course page "+course["course_url"])
        s_elts=OC_browser.find_elements_by_xpath("//div[contains(@itemprop,'articleBody')]//a[contains(@href,'/courses/') or contains(@href,'/cours/')]")
        if (len(s_elts)>0):
            for e in s_elts:
#                 print([course_id],"---->")
#                 print(e.text)
                href=e.get_attribute("href")
                if (href.find("openclassrooms.com/")>0):
                    tgt_course_id, tgt_chapter_id = extract_course_chapter_link(href)
#                     print(">---->")
                    req=e.find_elements_by_xpath("./ancestor::aside[@data-claire-semantic='warning']")
                    if len(req)>0:
#                         print("requires:",tgt_course_id, tgt_chapter_id,href )
                        required_entries.append([course_id,0,"requires",tgt_course_id,tgt_chapter_id,href])
                    else : 
#                         print("references:",tgt_course_id, tgt_chapter_id,href )
                        referenced_entries.append([course_id,0,"references",tgt_course_id,tgt_chapter_id,href]) 
                #end if link is on domain
        #end if 
        
        courses_counter+=1 
        set_progress(courses_counter+chapters_counter,'courses links')  
        
        # now iterate over chapters
        course_chapters = chapters[chapters["course_id"].isin([course_id])]
        for chapter_index, chapter in course_chapters.iterrows(): 
            
            OC_browser_get(chapter["chapter_url"],1.5,False)
#             print ("parsing chapter page "+chapter["chapter_url"])
            chapter_id=chapter["chapter_id"]
            # chapter page: collect required links and other links
            s_elts=OC_browser.find_elements_by_xpath("//div[contains(@itemprop,'articleBody')]//a[contains(@href,'/courses/') or contains(@href,'/cours/')]")
            if (len(s_elts)>0):
                for e in s_elts:
#                     print([course_id,chapter_id],"---->")
#                     print(e.text)
                    href=e.get_attribute("href")
                    if (href.find("openclassrooms.com/")>0):
                        tgt_course_id, tgt_chapter_id = extract_course_chapter_link(href)
#                         print(">---->")
                        req=e.find_elements_by_xpath("./ancestor::aside[@data-claire-semantic='warning']")
                        if len(req)>0:
#                             print("requires:",tgt_course_id, tgt_chapter_id,href )
                            required_entries.append([course_id,chapter_id,"requires",tgt_course_id,tgt_chapter_id,href])
                        else : 
#                             print("references:",tgt_course_id, tgt_chapter_id,href )
                            referenced_entries.append([course_id,chapter_id,"references",tgt_course_id,tgt_chapter_id,href]) 
                    #end if link is on domain
            #end if 
        
            chapters_counter+=1 
            set_progress(courses_counter+chapters_counter,'courses links')  
        #end iterating over Courses Chapters
        
        if (len(required_entries)>0):
            required_entries_counter+=len(required_entries)
            df_req=pd.DataFrame(required_entries, columns=ocd.OC_CoursesLinks_cols)
            ocd.OC_CoursesLinks=pd.concat([ocd.OC_CoursesLinks, df_req], ignore_index=True)
        if (len(referenced_entries)>0):
            referenced_entries_counter+=len(referenced_entries)
            df_ref=pd.DataFrame(referenced_entries, columns=ocd.OC_CoursesLinks_cols)
            ocd.OC_CoursesLinks=pd.concat([ocd.OC_CoursesLinks,df_ref], ignore_index=True)
        
#         if (courses_counter%10 ==0):
#             print([courses_counter, chapters_counter, required_entries_counter,referenced_entries_counter]) 

    #end iterating over Courses
    
    console_log("DONE :"+str(required_entries_counter)+" requirement links + "+str(referenced_entries_counter)+" other links collected") 
    
    OC_browser_disconnect()
    display_data_status()
    display_data_section()
    clear_progress()
    toggle_scrap_buttons(False)
    return success 
# fin fonction      

def scrap_OC_RepairCoursesLinks(b):
    from OCCoursesInterface  import console_log, display_data_status, display_data_section, set_progress, clear_progress, init_progress, toggle_scrap_buttons
    global OC_browser,  url_courses, url_paths, url_search, \
        search_language_options, search_topic_param, search_language_param, search_page_param, search_path_or_course_param\
    
    success=True #until it gets False
    
    missing = 0
    duplicates = 0
    df = ocd.OC_CoursesLinks[ocd.OC_CoursesLinks["tgt_course_id"].isin([0])]
    unique_missing_hrefs=df["href"].unique()
    missing = len(unique_missing_hrefs)

    dfd = ocd.OC_CoursesLinks[ocd.OC_CoursesLinks.duplicated(['src_course_id','src_chapter_id',"relation","href"], keep=False)]
    duplicates = len(dfd)

    if (missing>0):
        console_log("Scrapping "+str(missing)+" courses links to resolve broken references ") 
        resolved_entries=[]
        toggle_scrap_buttons(True)

        #start a browser to avoid window loading latency within the loop
        OC_browser_get(url_search)
        
        init_progress('repair links',0,0,missing)
        counter=0
        for href in unique_missing_hrefs:
            counter+=1
            set_progress(counter,'repair links')
            OC_browser_get(href)
            time.sleep(2) # let url resolution be done by server
            new_href=OC_browser.current_url 
            if (new_href!=href):
                tgt_course_id, tgt_chapter_id = extract_course_chapter_link(new_href)
                if tgt_course_id==0: # course id could not be resolved
                    tgt_course_id=-1 # so we will not ask again to resolve this course reference
                    tgt_chapter_id=-1
                entry=[tgt_course_id,tgt_chapter_id,href,new_href]
                resolved_entries.append(entry)
            else:
                tgt_course_id=-1 # so we will not ask again to resolve this course reference
                tgt_chapter_id=-1
                entry=[tgt_course_id,tgt_chapter_id,href,new_href]
                resolved_entries.append(entry) 
#         display("resolved entries ", resolved_entries)        
        for r in resolved_entries:
            indexes=ocd.OC_CoursesLinks[ocd.OC_CoursesLinks["href"].isin([r[2]]) & ocd.OC_CoursesLinks["tgt_course_id"].isin([0])].index.values    
#             display("updating ",indexes)
#             display("before",ocd.OC_CoursesLinks.loc[indexes,"tgt_course_id"])
            ocd.OC_CoursesLinks.loc[indexes,"tgt_course_id"]=r[0]
#             display("after",ocd.OC_CoursesLinks.loc[indexes,"tgt_course_id"])
            ocd.OC_CoursesLinks.loc[indexes,"tgt_chapter_id"]=r[1]
            
        console_log("DONE :"+str(len(resolved_entries))+" broken links resolved ") 
        OC_browser_disconnect()
    
    if (duplicates>0):
        console_log("Cleaning "+str(duplicates)+" duplicate courses links") 
        ocd.OC_CoursesLinks.drop_duplicates(subset = ['src_course_id','src_chapter_id',"relation","href"],inplace=True) 
        
    display_data_status()
    display_data_section()
    clear_progress()
    toggle_scrap_buttons(False)
    return success 
# fin fonction     


def scrap_OC_Paths(b): 
    from OCCoursesInterface  import console_log, display_data_status, display_data_section, set_progress, clear_progress, init_progress, toggle_scrap_buttons
    global OC_browser,  url_courses, url_paths, url_search, \
        search_language_options, search_topic_param, search_language_param, search_page_param, search_path_or_course_param
    
    success=True #until it gets False
    console_log("Scrapping paths") 
    toggle_scrap_buttons(True)
    # OC_Paths_cols = ["topic_id","path_id","path_name","path_description","path_language","path_level","path_duration_months","path_employment_warranty",
    # "path_partner","path_illustration","path_url","path_certification_url"]

    paths = []
    
    # start browser with fresh driver
    OC_browser_get(url_search+"?"+search_path_or_course_param+"=path")
    # the search page provides the total count of search results in a html element appearing only when window is phone-size
    # let's force this element to appear
    bs = OC_browser.get_window_size()
    print(bs)
    OC_browser.set_window_position(0, 0)
    OC_browser.set_window_size(640, 480)
    OC_browser_hide_overlays()
    time.sleep(2)
    nb_paths=0
    elt=OC_browser.find_element_by_xpath('//*[text() = "filtres (1)"]')
    elt.click()
    time.sleep(2)
    elt=OC_browser.find_element_by_xpath('//span[contains(string(),"Voir les")]')
    #elt=OC_browser.find_element_by_class_name("main-header-2-main-header168")
    # le texte ressemble Ã  : "voir les 471 rÃ©sultats"
    # le nb de rÃ©sultats est en 3eme position
    nb_paths=int(elt.text.split(" ")[2])
    # revenir Ã  la taille de dÃ©marrage pour retrouver les Ã©lÃ©ments de notre recherche
    OC_browser.set_window_size(bs["width"],bs["height"])
    init_progress('paths',0,0,nb_paths)
    
    # For each language
    for lang in search_language_options:
        console_log("LANG = "+lang)
        # get the topics available for this language
        OC_browser_get(url_search+"?"+search_language_param+"="+lang+"&"+search_path_or_course_param+"=path")
        time.sleep(2)
        elts=OC_browser.find_elements_by_xpath('//button[contains(string(),"ThÃ¨me")]/..//following-sibling::ul/li/span/button/span/span')
        topics = []
        for e in elts: 
            txt = e.get_attribute('innerHTML')
            topics.append(txt)
        #display("AVAILABLE TOPICS = ")
        #display(topics)
        # for each topic available for the given language
        for topic in topics:
            # identify the corresponding row in OC_Topics (to have a topic_id)
            topic_id=0
            for j in ocd.OC_Topics.index.values:
                if ocd.OC_Topics.topic_html_name.iloc[j] == topic:
                    topic_id=ocd.OC_Topics.iloc[j]["topic_id"]
                    break
            #display(OC_Topics.iloc[j])
            console_log("TOPIC = "+str(topic_id)+"/"+topic)
            # then get all search pages for this topic and this lang
            page_has_results=True
            page=1
            while (page_has_results):
                console_log("PAGE = "+str(page))
                page_has_results=False
                OC_browser_get(url_search+"?"+search_language_param+"="+lang+"&"+search_path_or_course_param+\
                               "=path"+"&"+search_topic_param+"="+topic.replace(" &amp; ","%20%26%20")+"&"+search_page_param+"="+str(page))
                time.sleep(2)
                OC_browser_hide_overlays()

                result_elts=OC_browser.find_elements_by_xpath('//ul/div/div') 
                #
                for re in result_elts:  
                    page_has_results=True
                    _elt=re.find_element_by_xpath('.//a[contains(@href,"/paths/")]')
                    path_url = _elt.get_attribute('href')
                    # format = xxxxidxxxx-name-of-the-course
                    path_url=path_url.rsplit('/', 1)[-1]
                    path_id=int(path_url.split('-')[0]) 
                    path_name=path_url.replace(str(path_id)+"-","") 
                    path_full_url=url_paths+path_url 
                    path_illustration= ""
                    _elt=re.find_element_by_xpath('.//figure') # 'figure' tag
                    fig_style=_elt.get_attribute("style")
                    if 'background-image' in fig_style:
                        path_illustration = fig_style.split(' url("')[1].replace('");', '') 
                    _elt=re.find_element_by_xpath('.//h6') # 'h6' tag
                    path_title=_elt.text 
                    
                    _elts=re.find_elements_by_xpath('.//a[contains(@href,"/paths/")]/span')
                    vect=[]
                    for _e in _elts:
                        vect.append(_e.text)
                    
                    path_level=""
                    path_duration=""
                    path_duration_months=0
                    path_employment_warranty=0
                    if (len(vect)>0):
                        path_level=vect[0]
                    if (len(vect)>1):
                        path_duration=vect[1]
                        val=path_duration.split(" ")[1]
                        path_duration_months=int(val)
                    if (len(vect)>2) and (vect[2] == "Emploi garanti"):
                        path_employment_warranty=1
                        
                    _elt=re.find_element_by_xpath('.//h6/following-sibling::div/span')
                    path_description=_elt.text
                    #some data are missing on the search page, so we'll fill the blanks when parsing each course page
                    path_date=""
                    path_partner=""
                    path_certification_url=""
                    path = [topic_id,path_id,path_name,path_date,path_title,path_description,lang,path_level,path_duration_months,
                            path_employment_warranty,path_partner,path_illustration,path_full_url,path_certification_url]
                    #display(course)
                    paths.append(path)
                    set_progress(len(paths),'paths')
                #end for page results
                page += 1
            #end while page has results
        # end loop on topics
    # end loop on language
    console_log("DONE :"+str(len(paths))+" paths collected")
    ocd.OC_Paths=pd.DataFrame(paths, columns=ocd.OC_Paths_cols)
    OC_browser_disconnect()
    display_data_status()
    display_data_section()
    clear_progress()
    toggle_scrap_buttons(False)
    return success 
# fin fonction

def scrap_OC_PathsSkills(b): 
    from OCCoursesInterface  import console_log, display_data_status, display_data_section, set_progress, clear_progress, init_progress, toggle_scrap_buttons
    global  OC_browser, url_courses, url_paths, url_search, \
        search_language_options, search_topic_param, search_language_param, search_page_param, search_path_or_course_param
    
    success=True #until it gets False
    console_log("Scrapping paths skills and some paths details") 
    toggle_scrap_buttons(True)
    # paths ["topic_id","path_id","path_name","path_date","path_title","path_description","path_language","path_level","path_duration_months","path_employment_warranty","path_partner","path_illustration","path_url","path_certification_url"]
    # paths skills ["path_id","skill"]
    entries = []
    
    #start a browser to avoid window loading latency within the loop
    OC_browser_get(url_search)
    
    # create a copy of iterable dataframe so that we can update the orginal
    df = ocd.OC_Paths[["topic_id","path_id","path_language","path_url"]].copy()
    init_progress('paths details',0,0,len(df))
    counter=0
    # iterate 
    for i , p in df.iterrows(): 
        counter+=1 
        OC_browser_get(p["path_url"])
        time.sleep(2)
        OC_browser_hide_overlays() 
        
        patterns=[]
        #beware it's really tricky to find good patterns!!! some little changes may break a lot!
        if (p["path_language"]=="fr"):
            patterns.append(("h2","CompÃ©tences"))
            patterns.append(("h2","Les compÃ©tences"))
            patterns.append(("h2","saurez"))
            patterns.append(("h2","faire"))
            patterns.append(("h2","Que vais-je apprendre"))
            patterns.append(("p","Ce que vous saurez faire")) 
            patterns.append(("h3","Ce que vous saurez faire"))
            patterns.append(("h2","capable de"))
            patterns.append(("h4","vous serez capable de"))
        elif (p["path_language"]=="en"):
            patterns.append(("h2","What will I learn"))
            patterns.append(("h2","What Will I Learn"))
            patterns.append(("h2","What you will learn"))
            patterns.append(("h2","What will I do"))
            patterns.append(("p","By the end of this path"))            
            patterns.append(("p","need to:"))
            patterns.append(("p","may be in charge of:"))  
            
        elts=None
        for tag, pattern in patterns:
            elts=OC_browser.find_elements_by_xpath('//'+tag+'[contains(string(),"'+pattern+'")]/following-sibling::*[position()<3]/descendant::li')
            if len(elts)>0:
                break; #elts matching tag+pattern found
        if (type(elts)==type(None)) or len(elts)==0:
            console_log("No skills found for this path! (pattern matching may have failed))") 
        else:
            # now some weird cooking. 
            # the first xpath expression gets all li elements following a tag containing a pattern
            # but when the li contains sublists, the top list text contains text from the child lists, 
            # so we remove the child text from the top list, knowing the child lists will be explored too 
            for e in elts:  
                txt=e.text 
                ses=e.find_elements_by_xpath('./descendant::li')
                for se in ses:
                    stxt=se.text 
                    txt=txt.replace(stxt,"")
                txt=txt.replace("\n","")
                if (txt!=""): 
                    entries.append([p["path_id"],txt]) 
            #end for elts
        #end else (elts found)
        
        # now let's try to complete missing data in the Paths dataframe
        # path_date="" #apparently no date around
        path_partner=""
        try:
            ptrn="xxxxxxxxxxxx"
            if (p["path_language"]=="fr"):
                ptrn="partenariat avec"
            elif (p["path_language"]=="en"):
                ptrn="partnership with"
            #todo : spanish when relevant
            elt=OC_browser.find_element_by_xpath('//figcaption[contains(string(),"'+ptrn+'")]')
            path_partner=elt.text.split(ptrn)[1]
            if path_partner.find(".")>0:
                path_partner=path_partner.split(".")[0]
            ocd.OC_Paths.loc[i,"path_partner"]=path_partner
        except:
            pass
        
        path_certification_url="" #example : https://www.certificationprofessionnelle.fr/recherche/rncp/27099
        try:
            elt = OC_browser.find_element_by_partial_link_text("RÃ©pertoire National des Certifications Professionnelles")
            path_certification_url=elt.get_attribute("href")
            ocd.OC_Paths.loc[i,"path_certification_url"]=path_certification_url
        except:
            pass
        
        set_progress(counter,'paths details')
    #end iterating over Paths dataframe

    console_log("DONE :"+str(len(entries))+" entries collected")
    print("DONE :"+str(len(entries))+" entries collected")
    ocd.OC_PathsSkills=pd.DataFrame(entries, columns=ocd.OC_PathsSkills_cols)
    OC_browser_disconnect()
    display_data_status()
    display_data_section()
    clear_progress()
    toggle_scrap_buttons(False)
    return success 
# fin fonction     

def scrap_OC_Projects(b):
    from OCCoursesInterface  import console_log, display_data_status, display_data_section, set_progress, clear_progress, init_progress, toggle_scrap_buttons
    global  OC_browser, url_courses, url_paths, url_search, \
        search_language_options, search_topic_param, search_language_param, search_page_param, search_path_or_course_param
    
    success=True #until it gets False
    console_log("Scrapping projects + skills") 
    toggle_scrap_buttons(True)
    # paths ["topic_id","path_id","path_name","path_date","path_title","path_description","path_language","path_level","path_duration_months","path_employment_warranty","path_partner","path_illustration","path_url","path_certification_url"]
    # projects ["path_id","project_id","project_number","project_name","project_title","project_description","project_duration_hours","project_illustration","project_url"]
    # projects skills ["path_id","project_id","project_number","skill"]
    p_entries = []
    ps_entries = []
    
    #start a browser to avoid window loading latency within the loop
    OC_browser_get(url_search)
    
    df = ocd.OC_Paths[["topic_id","path_id","path_language","path_url"]].copy()
    init_progress('projects',0,0,len(df))
    counter=0
    # iterate 
    for i , p in df.iterrows(): 
        counter+=1 
        OC_browser_get(p["path_url"]+"#path-tabs")
        time.sleep(3)
        OC_browser_hide_overlays() 
        time.sleep(1)

        #navigate to the "Projets" button and find a way to click on this hide-and-seek element
        OC_browser.execute_script("window.scrollBy(0,1000)", "") 
        elt = OC_browser.find_element_by_xpath("//button[@role='tab' and @aria-controls='path-overview-tab']/./..") # and contains(., 'AperÃ§u')
        location = elt.location
        OC_browser.execute_script("window.scrollBy(0,"+str(location["y"]+30)+")", "")
        time.sleep(1)
        elt = OC_browser.find_element_by_xpath("//button[@role='tab' and @aria-controls='path-project-tab']") # and contains(., 'Projets')
        elt.click()
        time.sleep(2)

        # now collect info
        path_id=p["path_id"]
        #project_id ne change pas dans cette fonction : le seul moment oÃ¹ un project_id reÃ§oit une valeur 
        # est lorsqu'on est connectÃ© Ã  un projet de son propre parcours
        project_id=0 
        
        elts=OC_browser.find_elements_by_xpath("//div/span/span[contains(.,'projet')]/../..")
        for re in elts:  
            e=re.find_element_by_xpath(".//span[contains(.,'projet')]")
            project_number=int(e.text.split(" ")[1]) 

            he= re.find_element_by_xpath(".//h3")
            project_title=he.text 

            e= he.find_element_by_xpath("./following-sibling::div[1]")
            project_description=e.text 

            e= re.find_element_by_xpath(".//span[contains(.,'heure')]") 
            project_duration_hours=int(e.text.split(" ")[0]) 
            
            p_entries.append([path_id,project_id,project_number,"",project_title,project_description,project_duration_hours,"",""])
            
            li_e=re.find_elements_by_xpath("../../following-sibling::*[contains(.,'CompÃ©tences acquises dans ce projet') and position()=1]//li")
            for e in li_e:
                ps_entries.append([path_id,project_id,project_number,e.text])
        #end loop on path projects
        set_progress(counter,'projects')
    #end iterating over Paths dataframe

    console_log("DONE :"+str(len(p_entries))+" entries collected") 
    ocd.OC_Projects=pd.DataFrame(p_entries, columns=ocd.OC_Projects_cols)
    ocd.OC_ProjectsSkills=pd.DataFrame(ps_entries, columns=ocd.OC_ProjectsSkills_cols)
    OC_browser_disconnect()
    display_data_status()
    display_data_section()
    clear_progress()
    toggle_scrap_buttons(False)
    return success 
# fin fonction     
 
# To use this function the user must be logged-in. 
def scrap_OC_ProjectsCoursesLinks(b): 
    from OCCoursesInterface  import console_log, display_data_status, display_data_section, set_progress, clear_progress, init_progress, toggle_scrap_buttons
    global OC_browser, OC_connexion_status, url_courses, url_paths, url_search, \
        search_language_options, search_topic_param, search_language_param, search_page_param, search_path_or_course_param
        
    if(OC_browser_get_connexion_status()==False): #not connected
        console_log("You must be connected to use this function! Please log in first.")
        return False
    
    success=True #until it gets False
    console_log("Scrapping projects courses links") 
    toggle_scrap_buttons(True)
    # paths ["topic_id","path_id","path_name","path_date","path_title","path_description","path_language","path_level","path_duration_months","path_employment_warranty","path_partner","path_illustration","path_url","path_certification_url"]
    # projects ["path_id","project_id","project_number","project_name","project_title","project_description","project_duration_hours","project_illustration","project_url"]
    # OC_ProjectsCoursesLinks_cols = ["path_id","project_id","project_number","course_id","href"]
    # OC_Courses_cols  = ["topic_id","course_id","course_name","course_date","course_title","course_description","course_language","course_difficulty", "course_duration_hours","course_author","course_partner","course_illustration","course_is_certified","course_url"]
    entries=[] 
    
    df = ocd.OC_Paths[["topic_id","path_id","path_language","path_url"]].copy()
    init_progress('projects links',0,0,len(df))
    counter=0
    # iterate 
    for i , p in df.iterrows(): 
        counter+=1 
        OC_browser_get(p["path_url"]+"#path-tabs")
        time.sleep(2)
        OC_browser_hide_overlays() 
        time.sleep(2)

        
        #navigate to the "Projets" button and find a way to click on this hide-and-seek element
        OC_browser.execute_script("window.scrollBy(0,1100)", "") 
        elt = OC_browser.find_element_by_xpath("//button[@role='tab' and @aria-controls='path-overview-tab']/./..") # and contains(., 'AperÃ§u')
        location = elt.location
        OC_browser.execute_script("window.scrollBy(0,"+str(location["y"]+50)+")", "")
        time.sleep(1)
        elt = OC_browser.find_element_by_xpath("//button[@role='tab' and @aria-controls='path-project-tab']") # and contains(., 'Projets')
        elt.click()
        time.sleep(2)

        # now collect info
        path_id=p["path_id"]
        #project_id ne change pas dans cette fonction : le seul moment oÃ¹ un project_id reÃ§oit une valeur 
        # est lorsqu'on est connectÃ© Ã  un projet de son propre parcours
        project_id=0 
        
        #find all section / @class= "learningPath__projectWrapper"
        elts=OC_browser.find_elements_by_xpath("//section[@class='learningPath__projectWrapper']")
        for re in elts:  
            # then find a subelement div / @class = "sideRibbon__content" to have the project number
            # the subelement is on the path : section > div > a > div > div > div > div / Projet 2
            e=re.find_element_by_xpath(".//div[@class='sideRibbon__content']")
            project_number=int(e.text.split(" ")[1]) 
            
            # then go to an element "div" having @class = learningPath__projectContent containing an element "a" @class = simpleCourseItem 
            # easier : @href of this element contains text /courses/ .... 
            s_elts=re.find_elements_by_xpath(".//a[contains(@href,'/courses/')]")
            if (len(s_elts)>0):
                for e in s_elts:
    #                 print([course_id],"---->")
    #                 print(e.text)
                    href=e.get_attribute("href")
                    if (href.find("openclassrooms.com/")>0):
                        course_id, tgt_chapter_id = extract_course_chapter_link(href)
    #                     print(">---->")
    #                     print("references:",tgt_course_id, tgt_chapter_id,href )
                          #["path_id","project_id","project_number","course_id","href"]
#                         print([path_id,project_id,project_number,course_id,href])
                        entries.append([path_id,project_id,project_number,course_id,href]) 
                    #end if link is on domain
                #end loop on links
        #end loop on projects sections
        set_progress(counter,'projects links')
    #end iterating over Paths dataframe

    console_log("DONE :"+str(len(entries))+" entries collected") 
    ocd.OC_ProjectsCoursesLinks=pd.DataFrame(entries, columns=ocd.OC_ProjectsCoursesLinks_cols)
    #ocd.OC_ProjectsCoursesLinks.to_csv("projects_courses_links.csv",index=False,sep="\t") 
#     OC_browser_disconnect()
    display_data_status()
    display_data_section()
    clear_progress()
    toggle_scrap_buttons(False)

    return success 
# fin fonction     

# --------------------------------------- "My Courses" follow-up  
# - as described here : https://openclassrooms.com/fr/courses/4525281-realisez-une-analyse-exploratoire-de-donnees/5148885-telechargez-les-jeux-de-donnees-analyses-dans-ce-cours
# - and here for the original javascript scrapper + python source code : https://github.com/stenier-oc/realisez-une-analyse-de-donnees-exploratoire 
# The purpose of this dataset is to track one's progression and explore related variables (see the notebook in mycourses/exploratory_analysis.ipynb)
# In the present Python program, we use Selenium to connect OC user dashboard and parse pages
# We use the SAME COLUMNS NAMES (in French) as in the datasets and scripts provided by OC (see the github source code), allowing these scripts to work properly (ACP stats, bags of words...) 
def scrap_OC_MyCourses(b):
    from OCCoursesInterface  import console_log, display_data_status, display_data_section, set_progress, clear_progress, init_progress, toggle_scrap_buttons
    global  OC_browser, url_courses, url_paths, url_search, \
        search_language_options, search_topic_param, search_language_param, search_page_param, search_path_or_course_param, url_my_paths ,url_my_courses 
    
    if(OC_browser_get_connexion_status()==False): #not connected
        console_log("You must be connected to use this function! Please log in first.")
        return False
    
    
    toggle_scrap_buttons(True)
 
    
    OC_browser_get(url_my_courses)
    time.sleep(10)
    OC_browser_hide_overlays()
    
    console_log("Scrapping My Courses")
     
    elts=OC_browser.find_elements_by_xpath('//table[@id="list-course-followed"]/tbody/tr')
    init_progress('my courses',0,0,len(elts))    
    counter=0
    mpc = [] #["course_id","start_date","progression"]
    mc  = [] #["titreCours","inscription","progression","moyenneDeClasse","duree","difficulte","nbChapitres","ratioQuizEvaluation","nbEvaluations","derniereMiseAJour","idCours"]
    mpp = [] #["path_id","project_number", "start_date","progression"]
    for re in elts: 
        counter+=1
        set_progress(counter,'my courses') 
        # --- data for MyProgressCourses
        course_id=0 # get from this page /
        start_date="" #/
        progression=0 #/
        # --- data for MyCourses 
        titreCours="" # to get from OC_Courses
        inscription="" # see start_date (and convert it into days counter since start date) / 
        # progression=0, # en commun avec MyProgressCourses /
        moyenneDeClasse=0 # never given by OC anymore /
        duree=0 # to get from OC_Courses
        difficulte=0 # to get from OC_Courses
        nbChapitres=0 # to get from OC_CoursesChapters
        ratioQuizEvaluation=0 # to get from OC_Courses  
        nbEvaluations=0 # to get from OC_Courses
        derniereMiseAJour="" # to get from OC_Courses
        idCours=0 # see course_id /
        ee=re.find_elements_by_xpath('.//td//a[contains(@href,"/courses/")]')
        if len(ee)>0:
            for eee in ee:
                href=eee.get_attribute("href") #format = "/fr/courses/4805776/next-page-to-do"
                href=href.replace("/next-page-to-do","")
                course_id=int(href.rsplit('/', 1)[-1])
                idCours=course_id
                break # we need just 1 course per TR
        #end if there is a course in this TR
        if course_id!=0:
            ee=re.find_element_by_xpath('.//td[contains(@class,"dashboardTable__infoSecondary")]')
            txt=ee.text
            start_date= datetime.strptime(txt, "%d/%m/%Y")
            today = date.today()
            sd=start_date.date()
            inscription = today - sd
            
            ee=re.find_element_by_xpath('.//td//div[contains(@class,"progressbar__rate")]')
            txt=ee.text.replace("%","").replace(" ","")
            progression=int(txt)
            
            df=ocd.OC_Courses[ocd.OC_Courses["course_id"]==course_id]
            if len(df)>0:
                for idx,r in df.iterrows():
                    titreCours=r["course_title"]
                    duree=r["course_duration_hours"]
                    difficulty=r["course_difficulty"]
                    if difficulty=='Facile':
                        difficulte=1
                    elif difficulty=='Moyenne':
                        difficulte=2
                    elif difficulty=='Difficile':
                        difficulte=3
                    derniereMiseAJour=r["course_date"]
                    # see https://github.com/stenier-oc/realisez-une-analyse-de-donnees-exploratoire
                    nbEvaluations=int(r["course_exercises_count"])+int(r["course_activities_count"])
                    nbQuiz=int(r["course_exercises_count"])
                    if (nbEvaluations>0):
                        ratioQuizEvaluation=nbQuiz/nbEvaluations
                    #now the chapters count
                    dfch=ocd.OC_CoursesChapters[ocd.OC_CoursesChapters["course_id"].isin([course_id])]
                    nbChapitres=len(dfch)                
                    break # just one course is needed, so break
            # end if a course was found
            mpc.append([course_id,start_date,progression])
            mc.append([titreCours,inscription,progression,moyenneDeClasse, \
                       duree,difficulte,nbChapitres,ratioQuizEvaluation,nbEvaluations,derniereMiseAJour,idCours])
        #end if the course id is valid
    # end loop over courses 

    console_log("DONE :"+str(len(mpc))+" entries collected") 
    ocd.OC_MyCourses=pd.DataFrame(mc, columns=ocd.OC_MyCourses_cols)
    ocd.OC_MyProgressCourses=pd.DataFrame(mpc, columns=ocd.OC_MyProgressCourses_cols)
     
        
    OC_browser_get(url_my_paths)
    time.sleep(5)
    OC_browser_hide_overlays()
    console_log("Scrapping My Projects")
    path_id=0
    elts=OC_browser.find_elements_by_xpath('//a[contains(@href,"/paths/")]')
    if len(elts)>0:
        for re in elts:
            href=re.get_attribute("href")
            path_url=href.rsplit('/', 1)[-1]
            path_id=int(path_url.split('-')[0]) 
            break #we just need the first link
    
    if (path_id>0):
        elts=OC_browser.find_elements_by_xpath('//a[contains(@href,"/projects/")]')        
        counter=0
        init_progress('my projects',0,0,len(elts)) 
        for re in elts: 
            counter+=1
            set_progress(counter,'my projects')
            txt=re.text
            status=""
            if txt.find("PROJET VALIDÃ")>=0 or txt.find("Projet validÃ©")>=0:
                status="done"
            elif txt.find("PROJET EN COURS")>=0 or txt.find("Projet en cours")>=0:
                status="in_progress"
            elif txt.find("PROJET Ã COMPLÃTER")>=0 or txt.find("Projet Ã  complÃ©ter")>=0:
                status="todo"
            mpp.append([path_id,counter,"",status])
        # end for
    #end if path_id>0
    
    console_log("DONE :"+str(len(mpp))+" entries collected") 
    ocd.OC_MyProgressProjects          = pd.DataFrame(mpp,columns=ocd.OC_MyProgressProjects_cols)    
    
    display_data_status()
    display_data_section()
    clear_progress()
    toggle_scrap_buttons(False)
#end scrapping my courses